{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Index","text":""},{"location":"#hello-im-tony","title":"Hello - I\u2019m Tony","text":"<p>Professionally, a Network Engineer with a passion for Python, open source stuff, indie games, boardgames, and radio. This site is mostly a reference for myself to remember how I got things to work. There's a chance it will help you too! (1)</p> <ol> <li>  The views, opinions, and positions expressed on this blog are my own and do not necessarily reflect the views, opinions, or positions of my employer or any other organization with which I am affiliated. All content provided on this blog is for informational purposes only and is not intended as professional advice.</li> </ol>"},{"location":"2024/05/15/advanced-rag/","title":"Advanced RAG","text":"<p>First things first... This is not advanced RAG. But it does mark an evolution in my ability, and feels advanced to 2024 Tony.</p> <p>The other day, I came across this post. It's a video of El Risitas guy, and the subtitles (included below) convey all the laughably ridiculous things people writing RAG apps today are doing.</p> <p>They split the file into chunks by page, or by paragraph or who the fuck knows. Embed it with <code>ada-002</code> for a couple cents. Store the embeddings in some hacked together database. They match your query by cosine similarity  and return the top k.  If the answer is bad ... they just increase the value of k!   Users have no idea how embeddings work, so they fill their query full of keywords expecting it to match but the top results are <code>README.md</code> and 5 <code>__init__</code> files so they switch to <code>text-embedding-3-large</code> and get a bigger disk  and performance gets worse. Convince their boss to pay for Pinecone,   still no beans! Still haven't added a keyword search!</p> <p></p> <p>Derisive tactics aside, having someone tell you how not to do something can help inform better approaches. I had confidently \"increased the value of k\" and \"switched to <code>text-embedding-3-large</code>\". Afterall, OpenAI says that's a best practice! Lest we forget... OpenAI will store your embedded data for $0.10/GB. That adds up quick when the default settings are:</p> <ul> <li>Model: <code>text-embedding-3-large</code></li> <li>Chunk Size: <code>800 tokens</code></li> <li>Chunk Overlap: <code>400 tokens</code></li> </ul> <p>With all this as a backdrop, here are some of my musings while learning how to do RAG.</p>"},{"location":"2024/05/15/advanced-rag/#where-to-begin","title":"Where to Begin?","text":"<p>For my use case, I have three goals:</p> <ol> <li>Ingest custom data</li> <li>Return accurate responses to user prompts</li> <li>Always include a citation in the response</li> </ol> <p>I'll be using LlamaIndex.  </p> <p>One of the better Getting Started resources I've found is this High-Level Concepts (RAG) page from the LlamaIndex docs. It covers, in general, the five 'stages' every RAG app will have:</p> <pre><code>flowchart LR\n    A[Loading] --&gt; B[Indexing] --&gt; C[Storing] --&gt; D[Querying] --&gt; E[Evaluating]</code></pre> <p>What you quickly discover, is each of these stages may have several steps (pipelines), and configuration varies widely. In the case of Querying, there are generally three sub-stages: Retrieval, Post Processing, and Response Synthesis. If we look at Retrieval, LlamaIndex covers 17 different Retrievers in their docs alone. Any of these can be used singularly, or combined for various effects and tactics you may want to employ when RAG-ing your data. Daunting, I know. But at least they've given us a framework to break things down.</p>"},{"location":"2024/05/15/advanced-rag/#common-pitfalls","title":"Common Pitfalls","text":"<p>There are a few patterns I've noticed that newbies encounter.</p> <ol> <li>Users want citations. The first way folks try to accomplish this, is by coaxing the llm to cite the response. \"Be sure to include the page where the answer was found.\" I've found this technique to be wildly inconsistent, and inaccurate.</li> <li>As your dataset increases... querying, and the steps you perform before that stage get much more complex. Early wins feel really great, but quickly dissolve as soon as you begin to scale.</li> <li>OpenAI develops really, really fast. The hurdle you solved for this week, may simply not exist next week. This creates a weird dynamic for prioritizing work</li> </ol>"},{"location":"2024/05/15/advanced-rag/#the-five-stages","title":"The Five Stages","text":""},{"location":"2024/05/15/advanced-rag/#loading","title":"Loading","text":"<p>Loading your data is part of the \"Ingestion Pipeline\" which includes: loading -&gt; transforming -&gt; indexing -&gt; storage. I've been scoping my loading stage to use LlamaIndex's <code>SimpleDirectoryReader</code> because it's straightforward to setup, and is general enough for my use case. Here's how we can load some data:</p> <pre><code>from llama_index.core import (SimpleDirectoryReader)\n\ndef load():\n    \"\"\"Stage 1: Load Data\"\"\"\n    documents = SimpleDirectoryReader(\"data\").load_data()\n    return documents\n\nif __name__ == \"__main__\":\n    print(load())\n</code></pre> <p>My data consists of rule books from GMT war games; Twilight Struggle, Churchill, and For the People. The data returned from <code>SimpleDirectoryReader</code> is a list of \"Documents\".</p> <p>LlamaIndex definition of a Document</p> <p>A Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders.</p> <p>In our case, the load stage returned a list of 116 documents which happens to equal the total pages for all three rule books. This must be how LlamaIndex handles PDFs when using the <code>SimpleDirectoryReader</code>.</p> Content of a LlamaIndex document<pre><code>Document(\n        id_='c7adc363-32e7-42b3-99fe-b356cd2f0be7',\n        embedding=None,\n        metadata={'page_label': '22', 'file_name': 'CHURCHILLRules-Final.pdf', 'file_path': 'C:\\\\projects\\\\learn-llama-index\\\\advanced-rag\\\\data\\\\CHURCHILLRules-Final.pdf', 'file_type': 'application/pdf', 'file_size': 2051633, 'creation_date': '2024-05-12', 'last_modified_date': '2024-05-12'},\n        excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'],\n        excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'],\n        relationships={},\n        text='Churchill Rules22\\n\u00a9 2015 GMT Games, LLC\\n10.0 Secret Agenda Variant \\nDESIGN NOTE: I have found gamers of two minds on games \\nwith continuous scoring like Churchill. Some folks like know-ing the exact score at all times and manage their decisions based on perfect \u2018score\u2019 information, whileothers like a bit more uncertainty. The core game uses perfect scoring but for those who like to have a bit more bluff in their games I offer the following official variant.\\n10.1 Secret Agenda Markers\\n \u2018Secret Agenda\u2019 markers are marked as such and also have the name of a country or colony on one side. Note that there are some duplicates for some countries/colonies; this is intentional and these are not extras.\\n10.2 Secret Agenda Procedure\\nTake the 36 Secret Agenda markers; each player secretly and randomly draws three markers. Do not show them to your op-ponents. At the end of the game before you determine the winner, all players reveal their Secret Agenda markers.10.3 Secret Agenda Scoring\\nIf at the end of the game a player has a Political Alignment marker in a country/colony that matches one of their Secret Agenda markers they score five additional points per marker, for a potential of 15 points if all three markers meet this condition. After these points have been applied to each players score the winner is determined.\\nPLAY NOTE: It is possible and intentional that the application of the Secret Agenda marker bonus could impact the condition under which the winner is determined, i.e.,    creates a 15 point difference in score that can change the winner. This fact needs to be incorporated into a player\u2019 s strategy, so be careful how hard you fight for your Secret Agenda.\\nPLAY NOTE: You score 5 VP per Secret Agenda marker, so if you have two markers for the same location, you would score 10 VP .\\nStalin and Churchill enjoy a private moment during the Yalta Conference.',\n        start_char_idx=None,\n        end_char_idx=None,\n        text_template='{metadata_str}\\n\\n{content}',\n        metadata_template='{key}: {value}',\n        metadata_seperator='\\n'\n)\n</code></pre> <p>The metadata returned here is pretty handy. My hope is that I'll be able to use this to accurately cite answers later.</p>"},{"location":"2024/05/15/advanced-rag/#indexing","title":"Indexing","text":"<p>Indexing typically involves generating embeddings. An Embedding \"is a vector (list) of floating point numbers. The distance between two vectors measures their relatedness.\" Send text in, get a load of floats back. Here's an example.  </p> <p>Note. I reduced the <code>dimensions</code> significantly to 30. By default, thousands of floats would be returned. <pre><code>tlofreso@MacBook-Pro:~$ curl https://api.openai.com/v1/embeddings \\\n&gt;   -H \"Content-Type: application/json\" \\\n&gt;   -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n&gt;   -d '{\n&gt;     \"input\": \"Once more unto the breach, dear friends, once more\",\n&gt;     \"model\": \"text-embedding-3-small\",\n&gt;     \"dimensions\": 30\n&gt;   }'\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"embedding\",\n      \"index\": 0,\n      \"embedding\": [\n        0.14859965,\n        0.25593004,\n        0.1891131,\n        0.10665011,\n        0.08737599,\n        0.0665146,\n        0.016647546,\n        0.15918152,\n        -0.25834873,\n        -0.018678887,\n        0.20302069,\n        -0.23854554,\n        -0.12834294,\n        -0.18593854,\n        0.21073033,\n        0.09992307,\n        -0.20029964,\n        0.08027103,\n        -0.13333154,\n        0.2108815,\n        -0.23340577,\n        0.13514556,\n        0.123429924,\n        0.012348661,\n        -0.26983762,\n        0.1795894,\n        -0.10135917,\n        -0.0073128263,\n        0.48374254,\n        -0.10302204\n      ]\n    }\n  ],\n  \"model\": \"text-embedding-3-small\",\n  \"usage\": {\n    \"prompt_tokens\": 11,\n    \"total_tokens\": 11\n  }\n}\ntlofreso@MacBook-Pro:~$ \n</code></pre></p> <p>By default LlamaIndex will use the <code>text-embedding-ada-002</code> model for embedding. I switched the embedding model to the new <code>text-embedding-3-small</code> because it's more capable, and 1/5th of the price. Changing the default chunk size, and overlap has a significant effect on the embeddings. OpenAI is using the <code>text-embedding-3-large</code> model, with chunk sizes of 800 and 50% overlap. While <code>text-embedding-3-large</code> is a more capable model, it takes up significantly more disk. For three files totaling <code>7.04mb</code> this is what you'll end up with for the various models and chunk configurations:</p>"},{"location":"2024/05/15/advanced-rag/#text-embedding-3-small","title":"text-embedding-3-small","text":"<pre><code>Default settings:                   5 files - 7.75mb\nchunk_size=1000, chunk_overlap=200: 5 files - 9.55mb\nchunk_size=800, chunk_overlap=400:  5 files - 11.5mb\nchunk_size=200, chunk_overlap=100:  5 files - 64.9mb\n</code></pre>"},{"location":"2024/05/15/advanced-rag/#text-embedding-3-large","title":"text-embedding-3-large","text":"<pre><code>Default settings:                   5 files - 14.3mb\nchunk_size=1000, chunk_overlap=200: 5 files - 17.9mb\nchunk_size=800, chunk_overlap=400:  5 files - 21.5mb\nchunk_size=200, chunk_overlap=100:  5 files - 124mb\n</code></pre>"},{"location":"2024/05/15/advanced-rag/#text-embedding-ada-002","title":"text-embedding-ada-002","text":"<pre><code>Default settings:                   5 files - 7.78mb\nchunk_size=1000, chunk_overlap=200: 5 files - 9.61mb\nchunk_size=800, chunk_overlap=400:  5 files - 11.6mb\nchunk_size=200, chunk_overlap=100:  5 files - 65.3mb\n</code></pre> <p>Here are the settings I ended up having the most success with: <pre><code>Settings.llm = OpenAI(model=\"gpt-4o\")\nSettings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\nSettings.text_splitter = SentenceSplitter(chunk_size=1000, chunk_overlap=200)\n</code></pre></p>"},{"location":"2024/05/15/advanced-rag/#storage","title":"Storage","text":"<p>For now, we're keeping storage simple. Right on the local filesystem. The code below will...</p> <ol> <li>Set the llm, embedding, and chunk config</li> <li>Load the data</li> <li>Generate the embeddings</li> <li>Store those embeddings on the filesystem</li> <li>Checks for existing embeddings, creates them if missing</li> </ol> <pre><code>import os\nfrom llama_index.core import (Settings, SimpleDirectoryReader, VectorStoreIndex, StorageContext)\n\nSettings.llm = OpenAI(model=\"gpt-4o\")\nSettings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\nSettings.text_splitter = SentenceSplitter(chunk_size=1000, chunk_overlap=200)\nPERSIST_DIR = \"./storage\"\n\ndef load():\n    \"\"\"Stage 1: Load Data\"\"\"\n    documents = SimpleDirectoryReader(\"data\").load_data()\n    return documents\n\ndef index(documents):\n    \"\"\"Stage 2: Index Data\"\"\"\n    index = VectorStoreIndex.from_documents(documents, show_progress=True)\n    index.storage_context.persist(persist_dir=PERSIST_DIR)\n\n\nif __name__ == \"__main__\":\n\n    # See if the index has been created, and create it if it hasn't\n    if not os.path.exists(PERSIST_DIR):\n        index(load())\n</code></pre>"},{"location":"2024/05/15/advanced-rag/#querying","title":"Querying","text":"<p>I have a lot to learn about querying. For the purposes of the goals outlined above, I was able to simply pass the index we're storing to a <code>query_engine</code> and the performance was pretty good.</p> <pre><code>storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\nindex = load_index_from_storage(storage_context)\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"How does Stalin's 'niet' ability work?\")\n</code></pre> <pre><code>------------------------\n\nPrompt: How does Stalin's 'niet' ability work?\n\nAnswer: Stalin's 'nyet' ability allows him to add a value of +1 when debating issues, reflecting his strong opposition and influence. This characteristic is used to move issues more effectively during\ndiscussions.\n\nCitation: CHURCHILLRules-Final.pdf - page 28\nCitation: CHURCHILLRules-Final.pdf - page 29\n\n------------------------\n</code></pre> <p>Nice! It works!  </p> <p>I don't show it here... but LlamaIndex includes in the response <code>text</code> word for word from the document. This is great because we can give the user a verbatim excerpt from the document they're inquiring about.</p>"},{"location":"2024/05/15/advanced-rag/#evaluating","title":"Evaluating","text":"<p>This is a stage for another day. Probably a future post once I get around to it :)</p>"},{"location":"2024/05/15/advanced-rag/#lessons-learned","title":"Lessons Learned","text":""},{"location":"2024/05/15/advanced-rag/#documents-with-similar-data-are-challenging","title":"Documents with Similar Data are Challenging","text":"<p>When dealing with documents that contains similar, but different data... it can be challenging to get relevant results. As an example, The Harmonie Group publishes law guides that provide insights on various legal topics at a state level. If you were to ingest the following files:</p> <pre><code>Ohio Harmonie Law Guide.pdf\nArizona Harmonie Law Guide.pdf\nIllinois Harmonie Law Guide.pdf\nDelaware Harmonie Law Guide.pdf\nWashington Harmonie Law Guide.pdf\nPennsylvania Harmonie Law Guide.pdf\n</code></pre> <p>And then write a prompt that says \"What is the statute of limitations in Ohio?\" the LLM will give you a summary of the statute of limitations laws, but it may not be for Ohio. If I upload 50 law guides, all of which contain statutes of limitation, things get muddy quickly with the returned responses. This is why citing the data is so important.</p> <p>Altering the <code>chunk_size</code> and <code>chunk_overlap</code> seemed to help solve this quite a bit. Post-processing in Python can help as well, simply removing responses that aren't relevant</p> <pre><code>if state not in response.response:\n    print(f\"State mismatch in response for {state}.\")\nelse:\n    print(f\"\\n\\n{response.response}\\n\\n\")\n    for node in response.source_nodes:\n        filename = node.node.metadata[\"file_name\"]\n        page = node.node.metadata[\"page_label\"]\n        print(f\"{filename} - page {page} - {state} in Filename? {state in filename}\")\n</code></pre> <p>Here's an article I came across that touches briefly on similar, but different data challenges: World's Most Accurate RAG?</p> <p>Cosine similarity is a popular strategy, but it has a big limitation; it\u2019s often tripped up by semantic similarity. Basically, cosine similarity can get confused if there are superficial similarities in two pieces of text. Because many of the documents contain information about tax information, it\u2019s likely that LangChain and LlamaIndex both got confused and simply returned a chunk which was irrelevant to the prompt.</p>"},{"location":"2024/05/15/advanced-rag/#embeddings-are-large","title":"Embeddings are Large","text":"<p>I was surprised when I matched my application's config to OpenAI's <code>chunk_size=800, chunk_overlap=400</code>, and the files I uploaded for embedding, returned 3x in size. In hindsight, they're reducing the dimensions as well, so it's likely not a 3-fold increase, but still something that needs considered.</p> <p>It's clear to me that enterprise RAG won't be as simple as embedding the entire network share. Some thought will go into whether something is embedded, and stored to disk... or embedded in memory on demand.</p>"},{"location":"2024/05/15/advanced-rag/#whats-next","title":"What's next?","text":"<p>I'm fairly motivated by the progress I've made. These are the things I want to work on next:</p> <ul> <li>Adding a frontend to my RAG app. There are many, I'll probably start with streamlit, flask, librechat, or openwebui.</li> <li>I'd like to learn more about data lifecycle management. Best practices for updating the embeddings of a newly modified file. Removing old embeddings, adding new files, etc.</li> <li>At some point I'll need to get embeddings into a proper database vs json files on my filesystem.</li> <li>Ingest data from additional sources</li> <li>Dive deeper on querying</li> <li>Figure an elegant way to evaluate output</li> </ul> <p>There's a lot to learn. It's overwhelming, but there are enough wins along the way that I'm able to stay excited about the work.</p>"},{"location":"2024/01/05/basic-linux-server-setup--hardening/","title":"Basic Linux Server Setup &amp; Hardening","text":"<p>Here are initial steps I perform on any fresh Linux install. My preferred distro is Debian, so anything below is within that context.</p>"},{"location":"2024/01/05/basic-linux-server-setup--hardening/#perform-updates-set-hostname-add-non-root-users","title":"Perform updates, set hostname, add non-root users","text":"<p>Perform updates <pre><code>apt update &amp;&amp; apt upgrade -y\n</code></pre> Configure hostname <pre><code>hostnamectl set-hostname debian\n#\n# vim /etc/hosts and add following line\n# &lt;ip-address&gt; debian\n#\n</code></pre> Add non-root users <pre><code>adduser my-username\nadduser my-username sudo\n</code></pre></p>"},{"location":"2024/01/05/basic-linux-server-setup--hardening/#configure-ssh","title":"Configure SSH","text":"<p>In order to secure SSH, I temporarily enable password auth to copy a non-root public key over. Once copied, I disable password auth, and disable root from authenticating via ssh</p> <ol> <li> <p>Temporarily enable password auth <pre><code># /etc/ssh/sshd_config\nInclude /etc/ssh/sshd_config.d/*.conf\nPermitRootLogin yes\nPasswordAuthentication yes\n</code></pre> Restart sshd with:  <pre><code>systemctl restart sshd\n</code></pre></p> </li> <li> <p>From client machine, copy-id for non-root account from client host <pre><code>ssh-copy-id my-username@&lt;ip-address&gt;\n</code></pre></p> </li> <li> <p>Reconfigure ssh to disable password auth, and disable remote root authentication <pre><code># /etc/ssh/sshd_config\nInclude /etc/ssh/sshd_config.d/*.conf\nPermitRootLogin no\nPasswordAuthentication no\n</code></pre> Restart sshd with: <code>systemctl restart sshd</code></p> </li> <li> <p>Lastly, enable passwordless sudo</p> </li> </ol> <pre><code># update default visudo editor to vim\nupdate-alternatives --config editor\n\n# use visudo to edit /etc/sudoers file\nvisudo\n\n%sudo    ALL=(ALL) NOPASSWD:ALL\n</code></pre>"},{"location":"2024/01/05/basic-linux-server-setup--hardening/#secure-server-with-host-firewall-ufw","title":"Secure server with host firewall UFW","text":"<p>Permit outbound traffic, deny all inbound traffic except SSH: <pre><code>sudo apt install ufw\nsudo ufw default allow outgoing\nsudo ufw default deny incoming\nsudo ufw allow ssh\nsudo ufw enable\nsudo ufw status\n</code></pre></p>"},{"location":"2024/11/30/getting-started-with-google-ai-studio/","title":"Getting Started with Google AI Studio","text":"<p>Google was a bit later than expected with widely available GenAI. They've rapidly gained momentum, and have several compelling models that lend themselves to interesting use cases. Here's a recent example of what I mean: Video Scraping.  </p> <p>Here are my notes for getting started with the Google AI Studio. </p> <p>Pro Tip - Create a New Google Account</p> <p>Google leverages Drive for prompt library, file storage, and chat history. Anthropic, and OpenAI will also authticate to a google drive for access to files. It's helpful to have a google account just for AI things. Create one here.</p>"},{"location":"2024/11/30/getting-started-with-google-ai-studio/#setup","title":"Setup","text":"<p>Developers should use Google AI Studio. This is analogous to the OpenAI Playground. There's a Python SDK (GH) available that may be installed with:</p> <pre><code>pip install -q -U google-generativeai\n</code></pre> <p>When you generate an API key, you'll be prompted to add it to a project. There's no concept of a default project like OpenAI / Anthropic. As far as I can tell, what Google means by \"project\" here is a Google Cloud Project. Similar to a Resource Group in Azure. The Google AI Studio will automatically spin a project up for you if one does not exist, and subsequently enable the Gemini API within that project. You can view this by visiting the Google Cloud Console. For me, it created a project called \"Gemini API\" in an Organization named \"No organization\". It also enabled the Gemini API within the project.</p> <p>Example Script </p> <p>The Gemini API Quickstart will walk you through creating the following script:</p> <pre><code>import google.generativeai as genai\nfrom dotenv import load_dotenv\nfrom rich import print\nimport os\n\nload_dotenv()\n\nAPI_KEY = os.getenv('API_KEY')\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\n\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\nresponse = model.generate_content(\"Write a story about a magic backpack.\")\n\nprint(response.text)\n</code></pre>"},{"location":"2024/11/30/getting-started-with-google-ai-studio/#people-to-follow","title":"People to Follow","text":"<p>The level of exposure the community has to the people building this tooling is remarkable. Here are several I follow:</p> <ul> <li>Raiza Martin - Product Lead for NotebookLM <sup>1</sup></li> <li>Josh Woodward - VP at Google Labs</li> <li>Logan Kilpatrick - Leed Product for Google AI Studio</li> </ul> <p>They are iterating incredibly fast, and are very open to community feedback. Here's a great example of a discussion between Logan and Pieter.</p>"},{"location":"2024/11/30/getting-started-with-google-ai-studio/#other-notes","title":"Other Notes","text":"<p>Gemini's free tier for developers is the most generous of any AI provider. This opens the door to some interesting use cases. I'm using the platform quite a bit... and time permitting, hope to write about the gems I find along the way.</p> <ol> <li> <p>Raiza has since left google to start her own company.\u00a0\u21a9</p> </li> </ol>"},{"location":"2024/01/01/my-home-network/","title":"My Home Network","text":"<p>In the past, I've used a variety of vendor provided hardware to work at the edge of my home network.  They're all too eager to give away free gear  in hopes of getting in the door of your employer. Anyways, it was high time I rolled my own HW.  </p> <p>My decision was a toss-up between raw linux on a Pi, or OPNsense on a mini PC. I opted for the latter...  Mostly due to the popularity around OPNsense / PFsense and some of the simplicity gains there. But also, Pi's  were hard to come by. A mini PC with more interfaces sounded great for a firewall, so I ordered a Qotom Q750G5</p> <p>Note</p> <p>Annectodally, if I were to pursue a Pi, I'd do something along these lines:  </p> <ul> <li>Jeff Geerling - Pi Simple Router </li> <li>Tall Paul Tech - Pi Router and Firewall</li> </ul>"},{"location":"2024/01/01/my-home-network/#the-hardware","title":"The Hardware","text":"<p>A new firewall was the genesis of my home network upgrades, which ultimately included new wifi, servers, and switches.</p>"},{"location":"2024/01/01/my-home-network/#firewall","title":"Firewall","text":"<p>The Qotom mini PC has 16GB of Ram, and a 64GB SSD. Memory has yet to crest 20% utilization in the months I've been running this box. For a good overview of the hardware, and OPNsense installation see this post by a fellow network engineer.</p>"},{"location":"2024/01/01/my-home-network/#switches","title":"Switches","text":"<p>My primary switch is a Ubiquiti US-8-150W. Great because it's fanless, has an internal power supply, and will do up to 30W of PoE per interface with a total power budget of 140W. There are a number of 5-port switch flex minis around the house as well to provide wired connectivity wherever I'd like.  </p> <p>Ubiquiti has had their fair share of rough spots over the years. I've been happy with the hardware, it's served me well... but come time to upgrade, I'll be hard pressed to buy from UI again for the following reasons: </p> <ol> <li>The TLDs...<code>www.ubiquiti.com</code> is not ubiquiti. They used to be <code>www.ubnt.com</code>... and you can still find content hosted under the ubnt TLD. They're now at ui.com - the transition was not smooth.</li> <li>Somewhere along the line they changed usernames to email addresses, which is fine, but also was not a smooth transition. </li> <li>The breaches in '21 were fairly harrowing. Eventually involving the FBI, and DOJ which you can read more about here.</li> </ol> <p>Anyways, YMMV. For the time being, the gear serves me well.</p>"},{"location":"2024/01/01/my-home-network/#servers","title":"Servers","text":"<p>Home lab \"servers\" are great these days. It's remarkable how much power / dollar you can buy. I purchased a pair of Dell Optiplex 7050s off ebay for under $100. Way more headroom than a pi, and not a whole lot more spendy. I also run Pi-hole on a Raspberry Pi 4B. Everything's mounted on a board in my basement, nice and tidy.</p>"},{"location":"2024/01/01/my-home-network/#nas","title":"NAS","text":"<p>My most recent edition, an AS6704T NAS from Asustor. I filled it with commodity grade 4TB HDs from Seagate, and two 500GB M2 drives for Read &amp; Write cache. I run SMB, AFP, NFS, SSH, and Jellyfin. It works great as a media server, with support for realtime transcoding. I was also able to get some stats in Grafana (more on that in another post):</p> <p> </p> <p>Lastly, I keep an offsite backup in an AWS S3 bucket. The Glacier Deep Archive tier storage is as cheap as it gets at roughly $1/1TB/Month.</p>"},{"location":"2024/01/01/my-home-network/#the-software","title":"The Software","text":"<p>I could (and maybe will) write a blog post for each piece of software identified here. These are all programs I've been wanting to run for some time, and finally this year I bought the servers, and allocated the time to do it.</p>"},{"location":"2024/01/01/my-home-network/#opnsense","title":"OPNSense","text":"<p>Right from their site OPNsense is an:</p> <p>open source, easy-to-use and easy-to-build FreeBSD based firewall and routing platform  </p> <p>I chose OPNsense over PFsense primarily because I know more people who run it. Updates are easy, and there's a built-in plugin marketplace that's quite handy. It's my stateful firewall, my DHCP server, and my wireguard VPN concentrator.</p>"},{"location":"2024/01/01/my-home-network/#pi-hole","title":"Pi-hole","text":"<p>Man, what a great project. And the level of detail put into onboarding / installation deserves applause. The bane of many OSS projects, is the level of expertise they require to get up and running. Pi-hole is a rare exception. Installing and configuring the software couldn't be easier, and if you end up needing help, the community is vast.</p>"},{"location":"2024/01/01/my-home-network/#netbox","title":"NetBox","text":"<p>I run this in production at work, and the maintainer is no stranger to any Network Engineer. Many of us have Jermey Stretch's cheatsheets hanging at our desks.</p> <p>NetBox was originally built as an IP Address Management (IPAM) application for Digital Ocean. It's now grown into a fully fledged DCIM platform. At home, I use it to document IP addresses on my network, but I also model every connected device with the Device Type Library. Once all devices are added, you can create cables, and generate cable traces so you know exactly where things are:</p> <p></p> <p>You can also setup panels on the homepage with quick links to services, or RSS feeds, etc... Check out more on the public demo site here!</p>"},{"location":"2024/01/01/my-home-network/#prometheus-grafana","title":"Prometheus / Grafana","text":"<p>I enjoy collecting data on the things around me. Whether it's Internet health, or Air quality, or the planes flying overhead... collecting data is fun! and visualizing it is even more fun. Having Grafana available to plot anything I want is great.</p> <p> </p> Dashboard of air quality around me with a baseline from the EPA"},{"location":"2024/01/01/my-home-network/#other","title":"Other","text":"<p>What's listed above comprises the primary network components. I'm running other software, like Home Assistant, and some open source Software Defined Radio applications, though I consider them seperate from my Home Network.</p> <p>\ud83c\udf89 -Happy New Year- \ud83c\udf89</p>"},{"location":"2024/08/19/i-napoleon/","title":"I, Napoleon","text":"<p>This isn't a review, or a post about my thoughts on the game. It's more a players guide. Something that's digital, mobile friendly, and a shortcut to many of the things I consistently look up in the official rulebook.</p>"},{"location":"2024/08/19/i-napoleon/#inital-setup","title":"Inital Setup","text":""},{"location":"2024/08/19/i-napoleon/#napoleons-luck","title":"Napoleon's Luck","text":"<p>Once per year, you may use Napoleon's Luck for any one of the following:</p> <ul> <li>To reroll any one Die Roll</li> <li>To immediately Ignore any one Mandatory Card just drawn and redraw a new card instead</li> <li>During the Campaign Resolution Phase, use Napoleon's Luck instead of paying the cost of any one Commander or Strategy &amp; Tactics card</li> </ul> <p>Napoleon's Luck may not be used after Abdication</p>"},{"location":"2024/08/19/i-napoleon/#game-ending-scenarios","title":"Game Ending Scenarios","text":"<p>The game immediately ends if any of the following occur at any point during the game:</p> <ul> <li>Card text explicitly noting that the game ends</li> <li>Glory reaches - during <code>FCD</code> or <code>EMD</code></li> <li><code>FCD</code> isn't triggered by the end of 1802</li> <li><code>EMD</code> isn't triggered by the end of <code>FCD</code></li> <li>Resolving certain cards will end the game (97, 156, 209, etc...)</li> <li>During Abdication</li> <li>At the conclusion of the Final Year</li> </ul>"},{"location":"2024/08/19/i-napoleon/#sequence-of-play","title":"Sequence of Play","text":"<p>This is a semi-detailed Sequence of Play that covers just enough to avoid referencing the rulebook.</p>"},{"location":"2024/08/19/i-napoleon/#year-setup-phase","title":"Year Setup Phase","text":"<p>This phase is skipped in the first year of any scenario.</p> <ol> <li>Advance the Year marker</li> <li>Reset the Card Draw marker</li> <li> <p>Take Resource Income</p> <ol> <li>May exchange Political for Administrative <code>1:1</code></li> <li>May exchange Glory for Administrative <code>3:1</code></li> </ol> </li> </ol> <p>Either Resource conversion may only yield up to a maximum combined total of 3 Admin points per year.</p>"},{"location":"2024/08/19/i-napoleon/#card-deck-phase","title":"Card Deck Phase","text":"<p>This phase is skipped in the first year of any scenario.</p> <ol> <li> <p>Remove Cards</p> <p>Years when cards are removed: 1794, 1795, 1796, 1802, 1803, 1813, 1814, 1815, 1816</p> </li> <li> <p>Add Cards</p> </li> <li> <p>Shuffle Draw Deck</p> <p>The game ends If</p> <ul> <li>Brumaire (47) has not been played by the end of CMD</li> <li>or if Imperial Plebiscite (110) has not been played by the end of FCD.</li> </ul> </li> </ol>"},{"location":"2024/08/19/i-napoleon/#card-action-phase","title":"Card Action Phase","text":"<ol> <li> <p>Draw a New Card and do what it says</p> A note on card costs <ul> <li>If the Cost of a Mandatory card can be paid, it must be paid.</li> <li>If the cost of a mandatory card cannot be paid, the card is Discarded and a new card is drawn without increasing the Card Draw marker.</li> <li>If you do not have enough to pay the cost (or do not want to pay the cost) of a non-Mandatory card, you cannot Play that card and must Discard it. However, on non-Mandatory cards, you do not redraw if you Discard the card.</li> </ul> </li> <li> <p>Play an Existing Card. Any Eligible, face-up Placed Cards on the map may now be Played, by resolving the Main Section. After Playing the card, be sure the Remove or Discard it, if required. If the card has an Ongoing Effect whcih can only Trigger once per Year, you may want to exhaust the card by rotating it as a reminder that its effect has been used.</p> </li> <li> <p>Phase Advancement Roll</p> A note on exhausted draw deck during CMD <p>In the extremely rare event that there are no cards left in the draw deck during this segment in the CMD Era, immediately skip to the Campaign Resolution Phase and Play Brumaire (47). If you cannot afford the combined 20G/P, the game immediately ends.</p> </li> </ol>"},{"location":"2024/08/19/i-napoleon/#campaign-resolution-phase","title":"Campaign Resolution Phase","text":"<p>If the Campaign Box is empty, skip to Campaign Clean-up... UNLESS Spanish Ulcer (221) is active.</p>"},{"location":"2024/08/19/i-napoleon/#assign-commanders","title":"Assign Commanders","text":"<p>Pay the cost indicated for every assigned commander regardless of use. Keep in mind A/G/P you may want to spend on Strategy &amp; Tactics.  </p> <p>If Spanish Ulcer Expeditions (221) is active, one Independent Commander must be assigned (if possible) to the SPAIN Box before any other Commander cards may be assigned to the curent campaign.</p>"},{"location":"2024/08/19/i-napoleon/#spanish-ulcer-expeditions-emd-only","title":"Spanish Ulcer Expeditions (EMD Only)","text":"<p>The Spanish Ulcer Expeditions (221) becomes active under two conditions:</p> <ul> <li>Spain Rises (199) is Played</li> <li>Spain becomes Hostile</li> </ul> <p>It remains active until the game ends, or Napoleon abdicates.  </p> <p>The Spanish Ulcer must be resolved during each Campaign Resolution Phase. </p> <ul> <li>Use any eligible cards in the BRITAIN Box, and any assigned Independent Commanders, along with any Strategy &amp; Tactics cards to determine DRMs. </li> <li>Apply the result of Success or Failure. Failure requires any one IC assigned to be randomly Discarded (unless Junot. He must be removed per card instructions). </li> <li>Used Commanders and Strategy &amp; Tactics cards are returned to their boxes, face-down.</li> </ul>"},{"location":"2024/08/19/i-napoleon/#campaign-resolution","title":"Campaign Resolution","text":"<ol> <li>Select Commanders among those assigned, pay attention to any indicated \"combat round\" restrictions</li> <li>Add Strategy &amp; Tactics Cards. Unlike Commander cards, these do not need added ahead of time, and may be reused in subsequent Combat Rounds. This is not always the case though... again, pay attention to combat round restrictions.</li> <li>Check Hostile Nation Effects (mid-late game)</li> <li>Check Campaign Modifiers for DRMs during specific Combat Rounds</li> <li>Determine Final DRM</li> <li>Flip Used Commanders Face-Down. That is: Flip all Commanders slected for the Combat Round face-down as a reminder that they may not be used in any subsequent Combat Round.</li> <li> <p>Combat Roll and Resolution</p> Modified DR Result Outcome 1 or less Bloody Defeat 2 Defeat 3-4 Bloody Stalemate 5-6 Stalemate 7-8 Bloody Victory 9 or more Victory </li> <li> <p>Check for Adjusted Result Some campaign modifier cards alter the outcome of a battle.  </p> <ul> <li>If both friendly and enemy cards can adjust the result, the enemy card's effect is applied first. This may mean that the Friendly card no longer adjusts the result, or that it now does adjust the result.</li> <li>If the final outcome was Bloody, place a Bloody Result marker near the Domestic Politics Table. This will <code>-1 DRM</code> for that phase. Bloody Result markers are not placed during CMD.</li> <li>If Victory, Treaty cards are Placed face-down in the CURRENT TREATIES Box. If the result calls for a Trety to be placed and it is not in the POTENTIAL TREATIES area of the board (because it was Placed preveiously, or Removed), the affected nation may be Conquered instead.</li> <li>If Stalemate, <code>-2G</code> and <code>-1 DRM</code> for the next combat round, and any subsequent combat rounds.</li> </ul> </li> </ol>"},{"location":"2024/08/19/i-napoleon/#commander-casualties","title":"Commander Casualties","text":"<p>Roll a D10 for all assigned commanders regardless of use. On 1, or 2 Commanders are discarded.</p>"},{"location":"2024/08/19/i-napoleon/#other-campaign-events","title":"Other Campaign Events","text":"<p>Resolve main section of any Campaign Modifiers with an effect that triggers after campaign resolution.</p>"},{"location":"2024/08/19/i-napoleon/#additional-campaign-resolution","title":"Additional Campaign Resolution","text":"<p>Sometimes multiple campaigns must be resolved. In this case:</p> <ul> <li>Place the new campaign</li> <li>Flip commanders used in the first campaign up (new commanders may not be added)</li> <li>Flip Strategy &amp; Tactics cards up. If they have a cost, it must be paid again</li> <li>Any campaign modifiers from the original campaign are discarded</li> </ul>"},{"location":"2024/08/19/i-napoleon/#campaign-cleanup","title":"Campaign Cleanup","text":"<ul> <li>Remove Campaign Modifiers, and Campaigns that have the \"when played\" icon in the bottom-right</li> <li>Return commanders and strategy &amp; tactics cards to their boxes face-up.</li> <li>Return Potential Campigns cards to their area</li> <li>Discard Campaign Modifiers that were not removed.</li> </ul>"},{"location":"2024/08/19/i-napoleon/#abdication-check","title":"Abdication Check","text":"<p>If the Campaign Resolution phase result was a Defeat in La Patrie en Danger (149), Game End has been triggered. Perform the Abdication Segment.</p>"},{"location":"2024/08/19/i-napoleon/#diplomatic-phase","title":"Diplomatic Phase","text":""},{"location":"2024/08/19/i-napoleon/#foreign-diplomacy","title":"Foreign Diplomacy","text":"<p>At the start of this phase, you may exchange:</p> <ul> <li>Glory for Diplomatic <code>3:1</code></li> <li>Political for Diplomatic <code>1:1</code></li> </ul> <p>for a maximum of one Diplomatic point per year. Diplomatic points may be spent to +1 DRM / point.</p> Modified DR Result 1 to 5 Remove Treaty or move the marker towards (or to) Hostile. 6 or more No effect."},{"location":"2024/08/19/i-napoleon/#current-treaties","title":"Current Treaties","text":"<ul> <li>Face-down treaties are not rolled.</li> <li>Roll for face-up treaties. On a modified DR of 1-5:<ul> <li>During <code>FCD</code>, move the marker towards Hostile</li> <li>During <code>EMD</code>, remove the treaty from the CURRENT TREATIES Box</li> </ul> </li> </ul> <p>Keeping track of the diplomatic landscape</p> <p>I find it helpful to rotate a nation's diplomacy marker if I'm not performing a diplomacy roll for some time. For example, after victory in Austria (Italy) Austria will be Neutral under The Treaty of Luneville until Napoleon becomes Emperor.</p>"},{"location":"2024/08/19/i-napoleon/#breaking-treaties","title":"Breaking Treaties","text":"<p>Napoleon may Remove any Treaty card in the CURRENT TREATIES Box. If you choose to do so:</p> <ul> <li>Set affected nations to Hostile</li> <li>Remove the treaty from the game</li> </ul>"},{"location":"2024/08/19/i-napoleon/#conquest","title":"Conquest","text":"<p>Austria, Prussia, and Britain may be Conquered. Conquering a nation results in +10G and +1P per nation to the player during the Resource Income segment.  </p> <p>Austria and Prussia If Austria and/or Prussia are defeated in a Campaign and no Potnetial Treaty card exists, the nation is considered Conquered. Flip its marker to its Conquered side. Austria or Prussia remain Conquered until:</p> <ul> <li>Napoleon suffers a Defeat in a Campaign</li> <li>Or cards:<ul> <li>Prussia Rises (198)</li> <li>English Gold Austria (188)</li> <li>English Gold (189)</li> </ul> </li> </ul> <p>Britain Britain can only be Conquered by playing Trafalgar (117) IF Nelson (36) is not face-up in the BRITAIN Box. Flip its marker to its Conquered side and remove the following cards from Play:</p> <ul> <li>John Moore (116)</li> <li>Wellington (118)</li> <li>English Expedition (131)</li> <li>Continental System (133)</li> <li>English Gold (Austria) (188)</li> <li>English Gold (189)</li> <li>Lines of Torres Vedras (193)</li> </ul> <p>A Conquered Britian remains Conquerted for the rest of the game.</p> <p>Russia and Spain Russia and Spain may never be Conquered. If no treaty, they remain Hostile. However:</p> <ul> <li>If Russia suffers a Defeat while Prussia and Austria are Conquered, flip its marker to \"Inactive\"</li> <li>Inactive Russia does not take part in any Campaigns until Austria or Prussia become Hostile.</li> <li>Inactive Russia is still considered Hostile for Domestic Politics</li> </ul>"},{"location":"2024/08/19/i-napoleon/#potential-campaigns","title":"Potential Campaigns","text":"<p>Determine whether or not a Potential Campaing card is Placed in the CAMPAIGN Box for next year. This is Optional during <code>FCD</code> but Mandatory during <code>EMD</code>.  </p> <p>FCD Potential Campaigns If Spain and/or Prussia is Hostile, you may pick either:</p> <ul> <li>Republican War with Prussia (70)</li> <li>Republican War with Spain (71)</li> </ul> <p>EMD Potential Campaigns Check the EMD Potential Campaigns Table below for Campaign selection. If the Diplomatic Status of a nation changes in the subesquent year, check for a better matching campaign card, and replace the current campaign.</p> Austria Prussia Russia Spain Potential Campaign to Select Hostile Allied, Neutral, Conquered Allied, Neutral, Inactive Any Austria Declares War (145) Hostile Hostile Allied, Neutral, Inactive Any Austria &amp; Prussia Declare War (146) Hostile Hostile Hostile Any Austria, Prussia, &amp; Russia Declare War (147) Hostile Allied, Neutral, Conquered Hostile Any Austria &amp; Russia Declare War (148) Conquered Allied or Neutral Hostile Any Austria &amp; Russia Declare War (148) - Place in the CAMPAIGN Box but Austria's cards may not be used when resolved. Any Any Any Any La Patrie en Danger (149) - Must Place when Triggered by a Campaign Result. Allied, Neutral, Conquered Allied, Neutral, Conquered Allied, Neutral, Inactive Hostile Napoleon in Spain (150) Any Any Any Any Polish Campaign (151) - May Place and resolve immediately when Triggered by Victory in Prussia and Russia Declare War (153). Allied, Neutral, Conquered Hostile Allied, Neutral, Inactive Any Prussia Declares War (152) Allied of Neutral Hostile Hostile Any Prussia &amp; Russia Declare War (153) Allied or Neutral Conquered Hostile Any Prussia &amp; Russia Declare War (153) - Place in the CAMPAIGN Box but Prussia's cards may not be used when resolved. Allied or Neutral Allied Hostile or Neutral Any Retreat From Russia (154) - Must Place and resolve immediately when Triggered by Stalemate or Defeat in Russia (155). Allied or Neutral Allied Hostile or Neutral Any Russia (155) - May Place in CAMPAIGN Box. -5 G if not played when possible. Conquered Conquered Hostile Any Roll a Die:  1-5: Austria &amp; Russia Declare War (148) - Place in the CAMPAIGN Box but Austria's cards may not be used when resolved.  6-10: Prussia &amp; Russia Declare War (153) - Place in the CAMPAIGN Box but Prussia's cards may not be used when resolved. Allied, Neutral, Conquered Allied, Neutral, Conquered Allied, Neutral, Inactive Allied or Neutral No EMD Campaign must be selected."},{"location":"2024/08/19/i-napoleon/#domestic-politics-phase","title":"Domestic Politics Phase","text":"<p>At the start of this phase, you may exchange:</p> <ul> <li>Admin for Political <code>2:1</code></li> <li>Glory for Political <code>3:1</code></li> </ul> <p>for a maximum of one Political point per year. Political points may be spent to +1 DRM / 2P spent. Calculate the Final DRM accounting for variables on the Domestic Politics Table. Then adjust Glory as follows:</p> Modified DR Result 0 or less \u201310 Glory 1-3 \u20135 Glory 4-6 \u20133 Glory 7-9 \u20132 Glory 10 or more No effect"},{"location":"2024/08/19/i-napoleon/#clean-up-phase","title":"Clean-Up Phase","text":"<ol> <li>Flip all face-down cards in the CURRENT TREATIES Box face-up</li> <li>Flip the Napoleon's Luck marker, if used, to its unused side</li> <li>Reset Admin and Diplomacy markers to zero (Admin is not reset in the first year)</li> </ol>"},{"location":"2024/08/19/i-napoleon/#links","title":"Links","text":"<ul> <li>Rulebook</li> <li>FAQ and Clarifications</li> </ul>"},{"location":"2024/08/19/i-napoleon/#interactions-on-bgg","title":"Interactions on BGG","text":"<p>Questions:</p> <ul> <li>Napoleon's Luck</li> <li>Josephine De Beauharnais' Death</li> <li>FCD Potential Campaigns</li> </ul> <p>General:</p> <ul> <li>Playbook Digital Copy</li> <li>Rulebook 14.7 Natural Frontiers - Typo</li> </ul>"},{"location":"2025/02/17/makemkv-and-ffmpeg/","title":"MakeMKV and FFmpeg","text":"<p>All of the physical media I own gets backed up to a NAS which is also a media server running Jellyfin. Recently, I upgraded my version of The Lord of the Rings. Here are some of my notes on ripping that media, and how I used FFmpeg to combine the multi-part films.</p>"},{"location":"2025/02/17/makemkv-and-ffmpeg/#the-hardware-and-software","title":"The Hardware and Software","text":"<p>The landscape for ripping Bluray media is a bear to navigate. It's a constant game of cat &amp; mouse knowing which drives are compatible, and what for... Especially in regards to UHD media. The MakeMKV forums are the best source I've found for help. Here's the latest from them: Flashing Guide Updated 2025.</p>"},{"location":"2025/02/17/makemkv-and-ffmpeg/#hardware","title":"Hardware","text":"<p>I own the following drives:</p> <ul> <li>Pioneer BDR-XD08UMB-S I cannot read UHD media with this drive. The FW is too new</li> <li>LG WP50NB40</li> </ul> <p>I can confirm, the LG drive with custom Firmware works great for ripping UHD media. I also have a Pioneer BDR-213/2213 on order with hopes of building a desktop loaded with 5.25\" drives.</p>"},{"location":"2025/02/17/makemkv-and-ffmpeg/#software","title":"Software","text":"<p>These three titles will get you a long way. The only one you must buy a license for is MakeMKV, and it's well worth it.</p> <ul> <li>MakeMKV - Ripping from disc to <code>movie.mkv</code> file</li> <li>HandBrake - Transcoding</li> <li>FFmpeg - Post processing utility</li> </ul>"},{"location":"2025/02/17/makemkv-and-ffmpeg/#combining-titles","title":"Combining titles","text":"<p>The Lord of the Rings is long. Each of the three films span multiple DVDs/Blurays. I don't want the films to be divvied into Part 1/Part 2 and luckily, they don't need to be once ripped to my NAS.  </p> <p>There are a couple things to consider:</p> <ul> <li>The two parts need to be combined</li> <li>The chapters need to be maintained</li> <li>The subtitle tracks need to be kept</li> </ul> <p>FFmpeg makes all this possible.</p>"},{"location":"2025/02/17/makemkv-and-ffmpeg/#getting-chapter-data","title":"Getting Chapter Data","text":"<p>Once you have the films as <code>.mkv</code> files, the chapter data can be extracted with these commands:</p> <pre><code>ffmpeg -i .\\part1.mkv -f ffmetadata part1_chapters.txt\nffmpeg -i .\\part2.mkv -f ffmetadata part2_chapters.txt\n</code></pre> <p>Here's a snipped of what the data looks like:</p> <pre><code>;FFMETADATA1\ntitle=The Lord of the Rings: The Two Towers (EXT.) PT. 1\nencoder=Lavf60.16.100\n[CHAPTER]\nTIMEBASE=1/1000000000\nSTART=0\nEND=248373125000\ntitle=Chapter 01\n[CHAPTER]\nTIMEBASE=1/1000000000\nSTART=248373125000\nEND=370703666666\ntitle=Chapter 02\n[CHAPTER]\nTIMEBASE=1/1000000000\nSTART=370703666666\nEND=884925708333\ntitle=Chapter 03\n</code></pre> <p>The timestamps are in nanoseconds. In order to maintain chapter data through both parts of the film, we need to append the Part 2 data to the end of Part 1 accounting for the delta in nanoseconds of the first part. Claude did a fantastic job writing a script to do this very task:</p> <pre><code>def combine_chapter_files(part1_path, part2_path, output_path):\n    \"\"\"\n    Combines two FFmpeg chapter metadata files, adjusting timestamps for the second file\n    based on the duration of the first file.\n    \"\"\"\n    def parse_chapter_file(filepath):\n        chapters = []\n        current_chapter = None\n        with open(filepath, 'r', encoding='utf-8') as f:\n            header = []\n            for line in f:\n                line = line.strip()\n                if line.startswith(';FFMETADATA1'):\n                    header.append(line)\n                elif line.startswith('title=') and not current_chapter:\n                    header.append(line)\n                elif line.startswith('encoder='):\n                    header.append(line)\n                elif line == '[CHAPTER]':\n                    if current_chapter:\n                        chapters.append(current_chapter)\n                    current_chapter = {'timebase': None, 'start': None, 'end': None, 'title': None}\n                elif current_chapter is not None:\n                    if line.startswith('TIMEBASE='):\n                        current_chapter['timebase'] = line\n                    elif line.startswith('START='):\n                        current_chapter['start'] = int(line.split('=')[1])\n                    elif line.startswith('END='):\n                        current_chapter['end'] = int(line.split('=')[1])\n                    elif line.startswith('title='):\n                        current_chapter['title'] = line\n            if current_chapter:\n                chapters.append(current_chapter)\n        return header, chapters\n\n    # Parse both files\n    header1, chapters1 = parse_chapter_file(part1_path)\n    _, chapters2 = parse_chapter_file(part2_path)\n\n    # Get the end time of the last chapter in part 1\n    offset = chapters1[-1]['end']\n\n    # Adjust timestamps for part 2 chapters\n    for chapter in chapters2:\n        chapter['start'] += offset\n        chapter['end'] += offset\n\n    # Write combined chapters to output file\n    with open(output_path, 'w', encoding='utf-8') as f:\n        # Write header (using header from part 1)\n        f.write('\\n'.join(header1) + '\\n\\n')\n\n        # Write all chapters\n        for chapter in chapters1 + chapters2:\n            f.write('[CHAPTER]\\n')\n            f.write(chapter['timebase'] + '\\n')\n            f.write(f\"START={chapter['start']}\\n\")\n            f.write(f\"END={chapter['end']}\\n\")\n            f.write(chapter['title'] + '\\n\\n')\n\n# Example usage:\ncombine_chapter_files('part1_chapters.txt', 'part2_chapters.txt', 'combined_chapters.txt')\n</code></pre>"},{"location":"2025/02/17/makemkv-and-ffmpeg/#combining-the-parts","title":"Combining the Parts","text":"<p>Now that we have all the chapter data, the parts can easily be combined into one epic film. First, I create a <code>filelist.txt</code> file like so:</p> <pre><code>file 'part1.mkv'\nfile 'part2.mkv'\n</code></pre> <p>Finally, we can combine the files...</p> <pre><code>ffmpeg \\\n    -f concat -safe 0 -i filelist.txt \\\n    -i combined_chapters.txt \\\n    -map 0:v -map 0:a -map 0:s? -map_metadata 1 \\\n    -c copy -analyzeduration 100M -probesize 100M \\\n    \"The Two Towers (2002).mkv\"\n</code></pre> <p>Here's a summary of what all that command is doing:  </p> <p>This command performs a concatenation (joining) of video files with some specific settings:</p> <ol> <li>The first line with <code>-f concat -safe 0 -i filelist.txt</code> tells ffmpeg to:<ul> <li>Use the concat demuxer format (<code>-f concat</code>)</li> <li>Disable \"safe mode\" (<code>-safe 0</code>) to allow absolute paths in the filelist</li> <li>Read the list of input files from <code>filelist.txt</code></li> </ul> </li> <li><code>-i combined_chapters.txt</code> loads a second input file containing metadata about chapters</li> <li>The mapping options (<code>-map</code> flags) specify which streams to include:<ul> <li><code>-map 0:v</code> includes all video streams from the first input</li> <li><code>-map 0:a</code> includes all audio streams</li> <li><code>-map 0:s?</code> includes all subtitle streams (if any exist)</li> <li><code>-map_metadata 1</code> copies metadata from the second input file</li> </ul> </li> <li>The final settings:<ul> <li><code>-c copy</code> uses stream copying (no re-encoding)</li> <li><code>-analyzeduration 100M</code> and <code>-probesize 100M</code> increase the analysis buffer size for large files</li> <li>The output is saved as \"The Two Towers (2002).mkv\"</li> </ul> </li> </ol> <p>And that's a wrap.</p>"},{"location":"2024/01/06/people-i-follow/","title":"People I Follow","text":"<p>This list ended up being way longer than I anticipated. If I wrote about someone here, there's a good chance I've sponsored them in some way. Via Patreon, or buying merch, or books they've authored, etc... I would advocate that you do the same for interesting people that in some way, provide value to you.  All are simply ordered alphabetically.</p>"},{"location":"2024/01/06/people-i-follow/#bert-hubert","title":"Bert Hubert","text":"<p>I came across Bert's site via a post to Hackernews that linked to this article: Reverse Engineering the source code of the BioNTech/Pfizer SARS-CoV-2 Vaccine. Nowhere have I found a more concise and compelling depiction of how mRNA can be used to help humans fight pathogens. In '22, he wrote a fascinating little tool that beeps everytime google tracks you (demo here). More recently, he's spent time deep diving on climate change.</p> <p> -   -   -  </p> Topics Bert covers <p>Bert's topics are so broad, it's difficult for me to articulate in a bulleted list. But I've followed him for:</p> <ul> <li>mRNA Education</li> <li>Climate Science</li> <li>General Technology</li> </ul>"},{"location":"2024/01/06/people-i-follow/#corey-schafer","title":"Corey Schafer","text":"<p>Credited by much of the community with the best free Python tutorials available. Corey is very good at introducing a topic, then showing you a more elegant / advanced way to do the same thing. If you want to get started with web development, Corey's courses on Flask or Django are top notch. I also highly recommend his videos covering VS Code (win/mac).</p> <p> -   -  </p> Topics Corey covers <ul> <li>Python</li> <li>Flask</li> <li>Django</li> </ul>"},{"location":"2024/01/06/people-i-follow/#jeff-geerling","title":"Jeff Geerling","text":"<p>A tech generalist who regularly couples his educational videos with written blog posts (super helpful). He's authored a number of books, contributes to several open source projects, and is exteremely transparent about the challenges he's had with Crohn's... often raising money and advocating for folks going through similar struggles. He also does videos with his dad over at Geerling Engineering, a channel that covers awesome Radio stuff.</p> <p> -   -   -   -  </p> Topics Jeff covers <ul> <li>Ansible</li> <li>Home Automation</li> <li>Linux</li> <li>Raspberry Pi</li> <li>NAS</li> <li>Open Source Software</li> <li>Home Media Server</li> <li>Retro Gaming</li> </ul>"},{"location":"2024/01/06/people-i-follow/#kirk-byers","title":"Kirk Byers","text":"<p>Kirk has a great free course geared towards Network Engineers wanting to learn Python. He also offeres several paid courses covering Ansible, Python, Netmiko, and Nornir... helping folks get started with Network Automation.</p> <p> -   -  </p> Topics Kirk covers <ul> <li>Network Automation</li> <li>Python</li> </ul>"},{"location":"2024/01/06/people-i-follow/#scott-manley","title":"Scott Manley","text":"<p>A dev for Apple by trade, but he rarely ever talks about that. No, this Scotsman graces the Internet with an uncanny intellect for Space, Physics, and Flying. He's a go-to resource for summarized space happenings with Deep Space Updates - Space News. Scott recently acquired his private pilot certificate, and shared this fun post being recognized over radio by a Blackhawk pilot. Lastly, I will never not be jealous of his Lego livestream builds where he'll crack open an IPA, build for a few hours, and banter with his followers raking in a few hundred from super chats.</p> <p> -   -  </p> Topics Scott covers <ul> <li>Space News</li> <li>Physics</li> <li>Kerbal Space Program</li> <li>Flying</li> </ul>"},{"location":"2024/01/06/people-i-follow/#simon-sarris","title":"Simon Sarris","text":"<p>Professionally, Simon builds GoJS, but I follow for all the other things he spends time on. Primarily, the beautiful home he's built, but also, various writings and side projects:  </p> <ul> <li>Help Design My (Rose) Garden</li> <li>Careful Words</li> <li>grotto</li> </ul> <p> -   -   -  </p> Topics Simon covers <ul> <li>Homestead</li> <li>Wood Working</li> <li>Tech</li> </ul>"},{"location":"2024/01/06/people-i-follow/#simon-willison","title":"Simon Willison","text":"<p>Simon is developer behind Django, Datasette, and my favorite GenAI utility llm. What I find most impressive about Simon, is his insatiable curiosity and sheer output. His blog is vast. Covering everything from data journalism to fascinating experiments and creative use cases for GenAI tooling. Simon has a knack for breaking down complex topics into digestible pieces. He also actively shares his ongoing projects and ideas through weekly newsletters and TILs (Today I Learned).</p> <p> -   -  </p> Topics Simon covers <ul> <li>Data Journalism</li> <li>Django</li> <li>Datasette</li> <li>Generative AI</li> <li>Software Development</li> </ul>"},{"location":"2024/01/06/people-i-follow/#tall-paul-tech","title":"Tall Paul Tech","text":"<p>An unapologetically brash Austrailian who knows a ton about RF &amp; networking. Paul spends his time mounting Discone antennas, doing deep dives on packet captures, and occasionally plays music / cooks. If you're in networking, this playlist is a must. If you happen to live around Brisbane, he does do an annual meetup... Otherwise, you can find him on IRC.</p> <p> -  </p> Topics Paul covers <ul> <li>RTL SDR</li> <li>Tesla</li> <li>Solar</li> <li>LibreNMS</li> <li>Wireshark</li> <li>OSI Model</li> <li>Multicast</li> </ul>"},{"location":"2024/01/06/people-i-follow/#tim-urban","title":"Tim Urban","text":"<p>The mind behind Wait But Why. Long form blog posts that take really complex topics and break them down into bits anyone can understand. Check this one out all about the brain, or this one about energy production. He also recently authored a book.</p> <p> -   -  </p> Topics Tim covers <ul> <li>Life</li> <li>Human Nature</li> <li>Science</li> <li>Stick Figure Art</li> </ul>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/","title":"My Plans for the 2024 Solar Eclipse","text":"<p>This post is mostly a collection of my notes from here with a little more context throughout.  </p> <p>If you haven't heard, there's going to be a Total Solar Eclipse across North America on April 8th Get\u00a0Hyped! \ud83c\udf11</p> <p>I live near Cleveland, smack dab in the middle of totality. (yay!) There are many parks, and a massive lake to view the Eclipse from. There are also groups putting on events like the Great Lakes Science Center, and the Cuyahoga Astronomical Association.</p> <p>CAA members will bring telescopes, including solar telescopes.</p> <p>What a generous gesture!</p>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#gear-for-eclipse-day","title":"Gear for Eclipse Day","text":""},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#glasses","title":"Glasses","text":"<p>You must have glasses that are <code>ISO 12312-2</code> certified. Buy them now, the price won't go down. Here are two options:  </p> <ul> <li>these are the ones I bought</li> <li>these by American Paper Optics</li> </ul>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#apps","title":"Apps","text":"<p>There are two apps available for free, with an in-app purchase for a guided tour / push notifications for the 2024 eclipse.</p> <ul> <li> <p>Solar Eclipse Timer is the defacto standard for Solar Eclipse Apps.  </p> <p> </p> </li> <li> <p>The Eclipse App from The Planetary Society</p> <p> </p> </li> </ul>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#experiments","title":"Experiments","text":"<p>To Bring:  </p> <ul> <li>A white sheet, lay it on the ground to view Shadow Bands </li> <li>A colander or hand held cheese grater for Pinhole Projection </li> <li>High contrast green/red boards for Purkinje Effect </li> </ul>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#helpful-resources","title":"Helpful Resources","text":""},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#videos","title":"Videos","text":"<ul> <li>Smarter Every Day   What you need to know</li> <li>Jeff Geerling   How to shoot the eclipse \ud83d\udcf7 (see below)</li> <li>NASA   Official Broadcast on eclipse day</li> </ul>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#links","title":"Links","text":"<ul> <li>Interactive google map </li> <li>Smarter Every Day - Eclipse </li> <li>Smarter Every Day Checklist </li> <li>NASA 2024 Total Eclipse </li> <li>10 Rookie Mistakes</li> </ul>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#locations","title":"Locations","text":"<p>Ohio likely has the most people in totality outside of Texas.</p> <ul> <li>If you're in Youngstown, drive 5 miles North</li> <li>If you're in Canton, drive 5 miles North</li> <li>If you're in Columbus, drive 10 miles North</li> <li>If you're in Cincinnati, drive 15 miles North</li> </ul>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#potential-viewing-locations","title":"Potential Viewing Locations","text":""},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#sharon-nature-preserve","title":"Sharon Nature Preserve","text":"<p>6734 State Road Sharon Township, OH</p> <p>134 acre property with open hay fields, and a wildflower meadow</p>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#silver-creek-disc-golf-course","title":"Silver Creek Disc Golf Course","text":"<p>4579 Medina Line Rd. Norton, OH 44203</p> <p>The Disc Golf Course is an open field. Another option would be the fields south of the pheasant run trail.</p>"},{"location":"2024/03/15/my-plans-for-the-2024-solar-eclipse/#maps","title":"Maps","text":"<p>Path over Ohio </p> <p>Path over US </p>"},{"location":"2025/05/05/running-llms-locally/","title":"Running LLMs Locally","text":"<p>This is a short post on how I've setup llms to run locally.</p>"},{"location":"2025/05/05/running-llms-locally/#prerequisites","title":"Prerequisites","text":"<p>There are two tools that make this trivial: UV, and LLM. Start by installing them:</p> <pre><code># Install UV:\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Set Python 3.12 as the default:\nexport UV_PYTHON=3.12\nsource ~/.bashrc\n\n# Install LLM as a UV tool:\nuv tool install llm --python 3.12\n</code></pre> <p>Corey Schafer has a great overview of UV, and why you may choose to use it Corey Schafer - Python Tutorial: UV </p> <p>Detailed installation documentation for LLM and UV:</p> <ul> <li>UV Installation</li> <li>LLM Installation</li> </ul>"},{"location":"2025/05/05/running-llms-locally/#installing-the-models","title":"Installing the Models","text":"<p>Apple's MLX (GH) is a framework for running ML workloads efficiently on Apple silicon. It's the underlying technology that makes this all work so well (even on my 4yo macbook). Simon talks about this in a bit more detail:</p> <p>The challenge with these models is not RAM, it's GPU-available RAM. Apple Silicon makes system RAM available to the GPU, which is why Apple hardware (thanks to MLX) is good for running these models. On non-Apple machines I think you would need 600+ GB or VRAM to run this model [DeepSeek v3 0324]</p> <p>The LLM tool we installed before has a plugin for MLX. We'll use this in tandem with models from Hugging Face.</p> <pre><code># Install the plugin\nllm install llm-mlx\n\n# Download two models\nllm mlx download-model mlx-community/gemma-3-27b-it-qat-4bit\nllm mlx download-model mlx-community/Qwen3-8B-4bit\n\n# Setup aliases\nllm aliases set q3 mlx-community/Qwen3-8B-4bit\nllm aliases set g3 mlx-community/gemma-3-27b-it-qat-4bit\n</code></pre>"},{"location":"2025/05/05/running-llms-locally/#usage","title":"Usage","text":"<p>Now we can use the models like so:</p> <pre><code>tlofreso@MacBook-Pro-3:~$ llm -m g3 \"What is the meaning of life? Answer in a single number.\"\n42. \n</code></pre>"},{"location":"2025/05/05/running-llms-locally/#the-models","title":"The Models","text":"<p>The models I chose are from the Gemma3 and Qwen3 families. I chose them due to the consensus on Twitter/X being these are two of the most capable models that will fit on my 32GB macbook. Gemma weighs in at around 14GB of memory consumption, and Qwen slightly under 5GB.</p>"},{"location":"2025/05/05/running-llms-locally/#links","title":"Links","text":"<ul> <li>MLX on Hugging Face: MLX Community</li> <li>Gemma3 Family Models</li> <li>Quen3 Family Models</li> <li>Simon on Gemma3: Gemma3 QAT Models</li> <li>Simon on Qwen3</li> </ul>"},{"location":"2025/05/05/running-llms-locally/#credits","title":"Credits","text":"<p>I referenced two personalities in this post that I've wrote about before. Simon Willison and Corey Schafer. Just wanted to highlight here that they continue to be a steadfast source of great information.</p>"},{"location":"2024/01/30/speech-to-text-using-whisper/","title":"Speech to Text using Whisper","text":"<p>This year, I've had fun finding ways to use OpenAI tooling in everyday life. For most folks, this means interacting with ChatGPT through the app, or in a web browser at https://chat.openai.com. For me, it's been learning how to effectively use the tools programmatically. One of those tools, is  Whisper.  Whisper will take an audio file (up to 25MB) and transcribe the audio into text. Contained here, is how I use Whisper, with other tooling, to convert voice memos I've recorded in iOS to text, then subsequently summarize the text into meeting minutes.</p>"},{"location":"2024/01/30/speech-to-text-using-whisper/#tech-stack","title":"Tech Stack","text":"<p>For this workflow, I use Dropbox as short-term storage, GitHub actions to run all the tasks, and Open AI's Whisper / GPT-4 models to do the actual work. The sequence of events looks something like this (click for larger image):  </p> <p></p> <p></p> Mermaid diagram code <pre><code>sequenceDiagram\n    participant VoiceMemos as Record a Voice Memo\n    participant Dropbox as Dropbox\n    participant GitHubAction as GitHub Action\n    participant Whisper as Whisper\n    participant GPT4 as GPT-4\n    VoiceMemos-&gt;&gt;Dropbox: Share audio to Dropbox\n    Dropbox-&gt;&gt;GitHubAction: Download audio\n    activate GitHubAction\n    GitHubAction-&gt;&gt;Whisper: Transcribe audio using Whisper\n    activate Whisper\n    Whisper--&gt;&gt;GitHubAction: Return transcript\n    deactivate Whisper\n    GitHubAction-&gt;&gt;GPT4: Create meeting minutes from transcript\n    activate GPT4\n    GPT4--&gt;&gt;GitHubAction: Return meeting minutes\n    deactivate GPT4\n    GitHubAction--&gt;&gt;Dropbox: Upload meeting minutes\n    deactivate GitHubAction\n</code></pre>"},{"location":"2024/01/30/speech-to-text-using-whisper/#dropbox-app","title":"Dropbox App","text":"<p>For long-lived Dropbox API interactions, you'll need a Dropbox App. A bit much for my use case... I wish there were an easier way to interact with Dropbox programmatically, but if you want to use the API, you need oauth, and you get oauth by having an app_key/app_secret pair. At a very high level, here are the steps:</p> <ol> <li>Create an app using the App Console</li> <li> <p>Retrieve the App key and App secret in your Dropbox app's settings, and use the app key to create an Authorization URL: <pre><code>https://www.dropbox.com/oauth2/authorize?client_id=&lt;APP_KEY&gt;&amp;token_access_type=offline&amp;response_type=code\n</code></pre></p> </li> <li> <p>Complete the auth-z flow by browsing to the Authorization URL. You'll receive an <code>authorization_code</code> at the end.</p> </li> <li>Make a <code>POST</code> call to <code>https://api.dropboxapi.com/oauth2/token</code> with the appropriate parameters: <code>APP_KEY</code>, <code>APP_SECRET</code>, <code>AUTHORIZATION_CODE</code> <pre><code>BASIC_AUTH=$(echo '&lt;APP_KEY&gt;:&lt;APP_SECRET&gt;' | base64) # Encode username:password\ncurl --location --request POST 'https://api.dropboxapi.com/oauth2/token' \\\n     --header 'Authorization: Basic $BASIC_AUTH' \\\n     --header 'Content-Type: application/x-www-form-urlencoded' \\\n     --data-urlencode 'code=&lt;AUTHORIZATION_CODE&gt;' \\\n     --data-urlencode 'grant_type=authorization_code'\n</code></pre> The response for this call will include a <code>refresh_token</code> ... <pre><code>{\n  \"access_token\": \"sl.***\",\n  \"token_type\": \"bearer\",\n  \"expires_in\": 14400,\n  \"refresh_token\": \"***\",\n  \"scope\": \"&lt;SCOPES&gt;\",\n  \"uid\": \"***\",\n  \"account_id\": \"***\"\n}\n</code></pre> Use the refresh token in your code. The Dropbox Python SDK has support for this: <pre><code>import dropbox\n\ndropbox_client = dropbox.Dropbox(\n  app_key=config['dropbox_app_key'],\n  app_secret=config['dropbox_app_secret'],\n  oauth2_refresh_token=config['dropbox_refresh_token']\n)\n</code></pre></li> </ol> <p>Here are some links I found helpful while creating my app:</p> <ul> <li>Handy oauth post</li> <li>also useful</li> <li>getting a token</li> </ul>"},{"location":"2024/01/30/speech-to-text-using-whisper/#openai-whisper","title":"OpenAI Whisper","text":"<p>OpenAI's documentation is pretty great.</p> <ul> <li>Here are the docs for the endpoint I'm using Create transcription.</li> <li>Here's a more in-depth example of how to use the endpoint: Speech to text</li> </ul> <p>This is my code</p> <pre><code>from openai import OpenAI\n\nopenai_client = OpenAI()\n\ndef transcribe_audio(file, prompt=None):\n    print(\"Starting transcribe...\")\n    with open(file, \"rb\") as file:\n        transcript = openai_client.audio.transcriptions.create(model = \"whisper-1\", file=file, prompt=prompt)\n\n    return transcript.text\n</code></pre>"},{"location":"2024/01/30/speech-to-text-using-whisper/#github-actions","title":"GitHub Actions","text":"<p>I like GitHub quite a bit. Public repos get access to some great tooling like Dependabot, and up to 2,000 minutes / month for GitHub Action Runners. I have a goal this year to use GitHub Actions more.</p> <p>The action below runs on demand (with <code>worflow_dispatch</code>) or every day at 5PM <code>schedule</code> uses UTC time. The <code>setup-python</code> action is pretty slick as it takes advantage of GitHub's Hosted tool cache feature. This improves the total runtime of your jobs by caching the full dev environment instead of downloading/installing for each run.</p> <pre><code>name: Speech to Text Runner\nrun-name: Transcribe audio file to text\non:\n  schedule:\n      - cron: '0 22 * * *'\n  workflow_dispatch:\nenv:\n  DROPBOX_APP_KEY: ${{ secrets.DROPBOX_APP_KEY }}\n  DROPBOX_APP_SECRET: ${{ secrets.DROPBOX_APP_SECRET }}\n  DROPBOX_REFRESH_TOKEN: ${{ secrets.DROPBOX_REFRESH_TOKEN }}\n  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\njobs:\n  Audio-Transcriber:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'\n      - run: pip install -r requirements.txt\n      - name: Run Main\n        run: python main.py\n</code></pre>"},{"location":"2024/01/30/speech-to-text-using-whisper/#enhancing","title":"Enhancing","text":"<p>I quickly realized that support for larger audio files was going to be important for my use case. I also wanted to try GPT-4's hand at generating meeting notes for the transcripts.</p>"},{"location":"2024/01/30/speech-to-text-using-whisper/#adding-support-for-larger-files","title":"Adding Support for Larger Files","text":"<p>By default, Whisper supports files up to 25MB in size. I've found that 40 minutes is a good cutoff to stay under this limit when using the voice memos app in iOS. OpenAI has some guidance for Longer inputs. They recommend PyDub to chunk the audio.(1) They also recommend Prompting Whisper:</p> <ol> <li>ffmpeg is a dependency for PyDub</li> </ol> <p>To preserve the context of a file that was split into segments, you can prompt the model with the transcript of the preceding segment.</p> <p>Here's what I added for larger file support</p> <pre><code>from pydub import AudioSegment\nfrom pydub.utils import make_chunks\n\n# Takes a chunk duration in minutes, and a file as arguments.\n# Saves chunks to the working directory, and returns a list of filenames.\ndef chunk_audio(chunk_mins, file):\n    print(\"Chunking audio...\")\n\n    chunks_out = []\n\n    audio = AudioSegment.from_file(file)\n    chunk_size = chunk_mins * 60 * 1000\n    chunks = make_chunks(audio, chunk_size)\n    for i, chunk in enumerate(chunks):\n        audio_out = f'{i}.mp3'\n        chunk.export(audio_out, format='mp3')\n        chunks_out.append(audio_out)\n\n    print(f\"Chunked into {len(chunks_out)} files...\")\n    return(chunks_out)\n\nif __name__ == \"__main__\":\n\n    for file in audio_files:\n\n        chunks = chunk_audio(40, file)\n        transcripts = ['']\n\n        # Transcribe chunks with preceding chunk transcript as a prompt\n        for chunk in chunks:\n            transcript = transcribe_audio(file=chunk, prompt=transcripts[-1])\n            transcripts.append(transcript)\n</code></pre> <p>I also had to update my runner to install ffmpeg with this. Now the steps are:</p> <pre><code>steps:\n  - name: Checkout\n    uses: actions/checkout@v4\n  - name: Setup ffmpeg\n    uses: FedericoCarboni/setup-ffmpeg@v3\n  - name: Setup Python\n    uses: actions/setup-python@v5\n</code></pre>"},{"location":"2024/01/30/speech-to-text-using-whisper/#use-gpt-4-for-meeting-minutes","title":"Use GPT-4 for meeting minutes","text":"<p>Now that we have the full text for audio files of any size, we can use GPT-4 to summarize the content. Doing so was remarkably trivial. I followed this tutorial almost verbatim, and added three lines of Python to <code>main.py</code></p> <pre><code>from meeting_notes import meeting_minutes\nwith open(out_txt, \"r\") as full_transcript:\n     notes = meeting_minutes(full_transcript.read())\n</code></pre>"},{"location":"2024/01/30/speech-to-text-using-whisper/#cost","title":"Cost","text":"<p>My use of Dropbox and GitHub fall well within the free tiers. The spend in ChatGPT is quite low for what you get. Especially when you consider the sheer compute it takes to do the job: Transcribe, then Summarize. Here's where my January bill stands:</p> <ul> <li>26,600 transcribed seconds: $2.90</li> <li>274,600 tokens: $3.00</li> </ul> <p>Something else you'll quickly hit when using the APIs for anything other than trivial tasks, is Usage limits. Luckily, the ceiling for Tier 2 is quite high, and you can simply purchase $50 in API credits to unlock it.</p>"},{"location":"2023/12/30/this-blog/","title":"This Blog","text":"<p>A couple years ago, I stumbled upon Material for MkDocs. When the project added blog support last September, I became a sponsor and started authoring away. Now some 15 months later I'm finally getting around to configuring a proper build/deploy pipeline and actually getting this thing out the door. I've tried and abandoned personal blogging a number of times... hopefully, this time, it sticks.</p> <p>I don't have much to share on how this site is hosted. I follow this almost to a T. One obvious difference is the use of a custom domain. I got caught up for a bit getting this to work.</p> <p> </p> <p>Basically, I'd configure the domain name <code>www.tlofreso.com</code> at <code>&lt;my repo&gt;/settings/pages --&gt; Custom Domain</code>. This worked, until I would push an update to the site... then my custom domain settings would disappear. GitHub requires a <code>CNAME</code> file, which existed, but in the wrong location.</p> <p>MkDocs has a command line utility: <code>mkdocs gh-deploy</code> specifically built for the purpose of deploying your docs to GitHub Pages ( Great! ). The utility creates, and pushes a <code>gh-pages</code> branch to your repo, which is ultimately what serves the site. The <code>CNAME</code> file I'd created at project root did not exist in the <code>gh-pages</code> branch. I moved it to my <code>docs_dir</code> per the documentation.</p> project_root/docs/CNAME<pre><code>www.tlofreso.com\n</code></pre> <p>Success!</p>"},{"location":"2025/05/05/using-uv/","title":"Using UV","text":"<p>This post covers how I configure and use UV appropriately. Some of these tips are specifically useful within a corporate network.</p>"},{"location":"2025/05/05/using-uv/#setting-environment-variables","title":"Setting Environment Variables","text":"<p>Set these defaults:</p> <pre><code>export UV_DEFAULT_INDEX=https://my-internal-pypi-upstream.corp/pypi\nexport UV_INDEX=https://my-internal-pypi.corp/pypi-internal\nexport UV_NATIVE_TLS=true\nexport UV_PYTHON=3.12\n</code></pre>"},{"location":"2025/05/05/using-uv/#uv_default_index-uv_index","title":"UV_DEFAULT_INDEX &amp; UV_INDEX","text":"<p>UV_DEFAULT_INDEX configures UV to use this url as the default index for package installation. Typically in corporate environments, there will be some local pypi server you'll need to use. This is the setting to configure it as the default.</p> <p>UV_INDEX is a space seperated list of index URLs where UV may search for packages. Typically in a corporate environment, this would be the index url where internally developed libraries are kept.</p>"},{"location":"2025/05/05/using-uv/#uv_native_tls","title":"UV_NATIVE_TLS","text":"<p>UV_NATIVE_TLS configures UV to use the system's trust store. Important on corporate environments that employ SSL decrypt.</p>"},{"location":"2025/05/05/using-uv/#uv_python","title":"UV_PYTHON","text":"<p>UV_PYTHON lets you configure the default python version to use. By default, UV will use the latest available. This became problematic when Python 3.13 changed how it sets the ssl default_context. For now, I default all of my venvs to 3.12.</p>"},{"location":"archive/2025/","title":"2025","text":""},{"location":"archive/2024/","title":"2024","text":""},{"location":"archive/2023/","title":"2023","text":""},{"location":"category/genai/","title":"GenAI","text":""},{"location":"category/python/","title":"Python","text":""},{"location":"category/home-media/","title":"Home Media","text":""},{"location":"category/boardgames/","title":"Boardgames","text":""},{"location":"category/space/","title":"Space","text":""},{"location":"category/linux/","title":"Linux","text":""},{"location":"category/home-lab/","title":"Home Lab","text":""},{"location":"page/2/","title":"Index","text":""}]}